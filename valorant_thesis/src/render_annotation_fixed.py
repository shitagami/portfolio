# render_annotation_fixed.py
import cv2
import numpy as np
import json
import os

def create_tracking_highlight(base_video_path, json_path, output_path):
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("ğŸ“‚ JSONãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
    with open(json_path, "r") as f:
        data = json.load(f)
    
    events = data['events']
    trails = data['trails']
    fps = data['fps']
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã”ã¨ã«ã‚­ãƒ£ãƒ©ä½ç½®ã‚’è¾æ›¸åŒ–
    frame_map = {}
    for t in trails:
        f = t['frame']
        c = t['class']
        if f not in frame_map: frame_map[f] = {}
        frame_map[f][c] = {'x': t['x'], 'y': t['y']}
    print("âœ… è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã®æ•´ç†å®Œäº†")

    # å‹•ç”»èª­ã¿è¾¼ã¿
    cap = cv2.VideoCapture(base_video_path)
    clean_path = base_video_path.replace(".mp4", "_clean.mp4")
    if not os.path.exists(clean_path):
        print("âš ï¸ ã‚¯ãƒªãƒ¼ãƒ³å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚analyze_local_pt.pyã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        cap_clean = cv2.VideoCapture(base_video_path)
    else:
        cap_clean = cv2.VideoCapture(clean_path)

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))
    
    # --- è¨­å®š ---
    KILL_PRE  = int(fps * 3.0) 
    KILL_POST = int(fps * 3.0) 
    SPIKE_PRE = int(fps * 3.0)
    SPIKE_POST = int(fps * 2.0)
    FOCAL_PRE = int(fps * 5.0)   
    FOCAL_POST = int(fps * 3.0) 

    # â˜…å¤‰æ›´ç‚¹: ã“ã“ã§ã€Œé‡è¦ã‚¤ãƒ™ãƒ³ãƒˆåŒºé–“ã€ã‚’äº‹å‰ã«è¨ˆç®—ã—ã€ã‚¹ãƒ”ãƒ¼ãƒ‰èª¿æ•´ã‚’è¡Œã„ã¾ã™
    print("â±ï¸ 30ç§’ã«åã‚ã‚‹ãŸã‚ã®å†ç”Ÿé€Ÿåº¦ã‚’è¨ˆç®—ä¸­...")
    
    # å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã¤ã„ã¦ã€Œã‚¤ãƒ™ãƒ³ãƒˆä¸­ã‹ã©ã†ã‹ã€ã‚’åˆ¤å®šã™ã‚‹ãƒ•ãƒ©ã‚°é…åˆ—
    is_event_frame = np.zeros(total_frames, dtype=bool)

    for ev in events:
        start_f, end_f = 0, 0
        if ev['type'] == "spike_plant":
            start_f = ev['frame'] - SPIKE_PRE
            end_f   = ev['frame'] + SPIKE_POST
        elif ev['type'] == "focal_point":
            start_f = ev['frame'] - FOCAL_PRE
            end_f   = ev['frame'] + FOCAL_POST
        else: # kill events
            start_f = ev['frame'] - KILL_PRE
            end_f   = ev['frame'] + KILL_POST
        
        # é…åˆ—ç¯„å›²å†…ã«åã‚ã‚‹
        s = max(0, int(start_f))
        e = min(total_frames, int(end_f))
        is_event_frame[s:e] = True

    # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚«ã‚¦ãƒ³ãƒˆ
    event_frames_count = np.sum(is_event_frame) # ç­‰å€ã§å†ç”Ÿã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
    normal_frames_count = total_frames - event_frames_count # å€é€Ÿã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ æ•°

    TARGET_DURATION_SEC = 30.0
    target_total_output_frames = int(TARGET_DURATION_SEC * fps)

    # ã‚¤ãƒ™ãƒ³ãƒˆéƒ¨åˆ†ã ã‘ã§ä½•ç§’ä½¿ã†ã‹
    time_for_events = event_frames_count # 1ãƒ•ãƒ¬ãƒ¼ãƒ =1å‡ºåŠ›ãƒ•ãƒ¬ãƒ¼ãƒ 

    # æ®‹ã‚Šã®ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆç§»å‹•ãƒ‘ãƒ¼ãƒˆï¼‰ã«ä½¿ãˆã‚‹å‡ºåŠ›ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
    available_frames_for_normal = target_total_output_frames - time_for_events

    speed_multiplier = 1.0
    if available_frames_for_normal <= 0:
        print(f"âš ï¸ è­¦å‘Š: ã‚¤ãƒ™ãƒ³ãƒˆã‚·ãƒ¼ãƒ³ã ã‘ã§30ç§’ã‚’è¶…ãˆã¦ã„ã¾ã™ï¼({time_for_events/fps:.1f}ç§’)")
        print("ç§»å‹•ãƒ‘ãƒ¼ãƒˆã‚’æ¥µé™ã¾ã§ã‚«ãƒƒãƒˆã—ã¾ã™ã€‚")
        speed_multiplier = 100.0 # ã»ã¼ã‚¹ã‚­ãƒƒãƒ—
    else:
        # (ç§»å‹•ãƒ‘ãƒ¼ãƒˆã®å®Ÿãƒ•ãƒ¬ãƒ¼ãƒ æ•°) / (ä½¿ãˆã‚‹å‡ºåŠ›ãƒ•ãƒ¬ãƒ¼ãƒ æ•°) = å€é€Ÿãƒ¬ãƒ¼ãƒˆ
        speed_multiplier = normal_frames_count / available_frames_for_normal
        print(f"âœ… ã‚¤ãƒ™ãƒ³ãƒˆæ™‚é–“: {time_for_events/fps:.1f}ç§’, ç§»å‹•ãƒ‘ãƒ¼ãƒˆæ™‚é–“: {available_frames_for_normal/fps:.1f}ç§’")
        print(f"ğŸš€ ç§»å‹•ãƒ‘ãƒ¼ãƒˆã®å†ç”Ÿé€Ÿåº¦: {speed_multiplier:.2f}å€é€Ÿ ã«è¨­å®šã—ã¾ã—ãŸ")

    # --- ãã®ä»–ã®è¨­å®š ---
    MINIMAP_OFFSET_X = 0
    MINIMAP_OFFSET_Y = 0

    SMOOTH_FACTOR = 0.1     
    ZOOM_SIZE_PIXELS = 100  
    TARGET_ZOOM_LEVEL = width / (ZOOM_SIZE_PIXELS * 2) 

    current_zoom = 1.0
    cam_center_x = width / 2.0
    cam_center_y = height / 2.0

    COLOR_KILLER = (0, 255, 255) 
    COLOR_VICTIM = (0, 0, 255)   
    COLOR_ARROW  = (0, 255, 255) 
    COLOR_SPIKE  = (255, 0, 255) 
    COLOR_FOCAL  = (0, 255, 0)   
    COLOR_TEXT   = (255, 255, 255)
    
    TL_BG_COLOR     = (50, 50, 50)    
    TL_NORMAL_COLOR = (100, 100, 100) 
    TL_EVENT_COLOR  = (0, 0, 255)
    TL_FOCAL_COLOR  = (0, 255, 0)
    TL_CURSOR_COLOR = (255, 255, 255) 
    BAR_HEIGHT = 30

    def get_dynamic_pos(frame_idx, class_name):
        idx = int(frame_idx) # floatå¯¾å¿œ
        if idx in frame_map and class_name in frame_map[idx]:
            p = frame_map[idx][class_name]
            return {"x": p['x'] + MINIMAP_OFFSET_X, "y": p['y'] + MINIMAP_OFFSET_Y}
        return None

    def get_last_known_pos(frame_idx, class_name, lookback=30):
        idx = int(frame_idx)
        for i in range(lookback):
            target_f = idx - i
            if target_f < 0: break
            # å†…éƒ¨ã§intã‚­ãƒ£ã‚¹ãƒˆã—ã¦å‘¼ã¶
            pos = get_dynamic_pos(target_f, class_name)
            if pos: return pos
        return None

    # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ç”»åƒã®ç”Ÿæˆï¼ˆå›ºå®šï¼‰
    timeline_img = np.zeros((BAR_HEIGHT, width, 3), dtype=np.uint8)
    timeline_img[:] = TL_BG_COLOR 
    for ev in events:
        if ev['type'] == "focal_point":
            start_f = max(0, ev['frame'] - FOCAL_PRE)
            end_f   = min(total_frames, ev['frame'] + FOCAL_POST)
            x_start = int((start_f / total_frames) * width)
            x_end   = int((end_f / total_frames) * width)
            cv2.rectangle(timeline_img, (x_start, 0), (x_end, BAR_HEIGHT), TL_FOCAL_COLOR, -1)
    for ev in events:
        is_imp = ev['type'] in ["spike_plant", "kill", "multi_kill", "first_blood", "last_kill"]
        if is_imp:
            if ev['type'] == "spike_plant":
                start_f = max(0, ev['frame'] - SPIKE_PRE)
                end_f   = min(total_frames, ev['frame'] + SPIKE_POST)
            else:
                start_f = max(0, ev['frame'] - KILL_PRE)
                end_f   = min(total_frames, ev['frame'] + KILL_POST)
            x_start = int((start_f / total_frames) * width)
            x_end   = int((end_f / total_frames) * width)
            cv2.rectangle(timeline_img, (x_start, 0), (x_end, BAR_HEIGHT), TL_EVENT_COLOR, -1)

    print(f"--- å‹•ç”»ç”Ÿæˆé–‹å§‹ ---")
    
    # floatå‹ã§ãƒ•ãƒ¬ãƒ¼ãƒ ç®¡ç†ï¼ˆå°æ•°ç‚¹ä»¥ä¸‹ã®é€²è¡Œã‚’è¨±å®¹ã™ã‚‹ãŸã‚ï¼‰
    current_input_frame = 0.0
    output_frame_count = 0
    
    while current_input_frame < total_frames:
        current_frame_int = int(current_input_frame)
        
        # ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚¤ãƒ™ãƒ³ãƒˆæœŸé–“å†…ã‹ã©ã†ã‹
        in_event = is_event_frame[current_frame_int] if current_frame_int < total_frames else False
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—ï¼ˆè¡¨ç¤ºç”¨ï¼‰
        active_event = None
        candidates = []
        for ev in events:
            if ev['type'] == "spike_plant":
                start = ev['frame'] - SPIKE_PRE
                end = ev['frame'] + SPIKE_POST
            elif ev['type'] == "focal_point":
                start = ev['frame'] - FOCAL_PRE
                end = ev['frame'] + FOCAL_POST
            else: 
                start = ev['frame'] - KILL_PRE
                end = ev['frame'] + KILL_POST
            
            if start <= current_input_frame <= end:
                candidates.append(ev)
        
        if candidates:
            def get_priority(e):
                t = e['type']
                if t in ["kill", "multi_kill", "first_blood", "last_kill"]: return 100
                if t == "spike_plant": return 50
                if t == "focal_point": return 10
                return 0
            active_event = max(candidates, key=get_priority)
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ åŒæœŸèª­ã¿è¾¼ã¿
        cap.set(cv2.CAP_PROP_POS_FRAMES, current_frame_int)
        cap_clean.set(cv2.CAP_PROP_POS_FRAMES, current_frame_int)
        
        ret, frame_trails = cap.read()
        ret2, frame_clean = cap_clean.read()
        
        if not ret or not ret2: break
        
        # ã‚¤ãƒ™ãƒ³ãƒˆä¸­ã¾ãŸã¯ã‚ºãƒ¼ãƒ ä¸­ã¯ã‚¯ãƒªãƒ¼ãƒ³æ˜ åƒã€ãã‚Œä»¥å¤–ã¯è»Œè·¡ã‚ã‚Š
        if active_event:
            frame = frame_clean 
        else:
            frame = frame_trails 
        
        # --- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ±ºå®š & ã‚ºãƒ¼ãƒ ãƒ­ã‚¸ãƒƒã‚¯ ---
        target_center_x = width / 2.0
        target_center_y = height / 2.0
        target_zoom = 1.0
        ev_type = None
        
        if active_event:
            ev_type = active_event['type']
            target_pos = None

            if ev_type == "spike_plant":
                if active_event.get('k_pos'):
                    raw = active_event['k_pos']
                    target_pos = {"x": raw['x'] + MINIMAP_OFFSET_X, "y": raw['y'] + MINIMAP_OFFSET_Y}
            elif ev_type == "focal_point":
                if active_event.get('k_pos'):
                    raw = active_event['k_pos']
                    target_pos = {"x": raw['x'] + MINIMAP_OFFSET_X, "y": raw['y'] + MINIMAP_OFFSET_Y}
            else:
                killer_cls = active_event['killer']
                victim_cls = active_event['victim']
                kp = get_dynamic_pos(current_frame_int, killer_cls) or get_last_known_pos(current_frame_int, killer_cls)
                vp = None
                # ä½ç½®è£œå®Œãƒ­ã‚¸ãƒƒã‚¯
                if current_frame_int >= active_event['frame']:
                     vp = get_dynamic_pos(active_event['frame'], victim_cls) or get_last_known_pos(active_event['frame'], victim_cls, 30)
                else:
                     vp = get_dynamic_pos(current_frame_int, victim_cls) or get_last_known_pos(current_frame_int, victim_cls, 60)
                
                if not kp and active_event.get('k_pos'):
                    raw_k = active_event['k_pos']
                    kp = {"x": raw_k['x'], "y": raw_k['y']}
                if not vp and active_event.get('v_pos'):
                    raw_v = active_event['v_pos']
                    vp = {"x": raw_v['x'], "y": raw_v['y']}

                if ev_type in ["multi_kill", "first_blood"]: target_pos = kp
                else: target_pos = vp 
                if not target_pos: target_pos = kp if kp else vp

            if target_pos:
                target_center_x = target_pos['x']
                target_center_y = target_pos['y']
                target_zoom = TARGET_ZOOM_LEVEL

        # ã‚¹ãƒ ãƒ¼ã‚ºåŒ– (Viewer Timeã«å¯¾ã—ã¦ã‚¹ãƒ ãƒ¼ã‚ºã«å‹•ããŸã‚ã€ã“ã“ã¯æ¯ãƒ«ãƒ¼ãƒ—å®Ÿè¡Œã§OK)
        current_zoom = current_zoom * (1 - SMOOTH_FACTOR) + target_zoom * SMOOTH_FACTOR
        cam_center_x = cam_center_x * (1 - SMOOTH_FACTOR) + target_center_x * SMOOTH_FACTOR
        cam_center_y = cam_center_y * (1 - SMOOTH_FACTOR) + target_center_y * SMOOTH_FACTOR

        # åˆ‡ã‚ŠæŠœãå‡¦ç†
        crop_w = width / current_zoom
        crop_h = height / current_zoom
        x1 = max(0, min(cam_center_x - crop_w / 2, width - crop_w))
        y1 = max(0, min(cam_center_y - crop_h / 2, height - crop_h))
        x2 = x1 + crop_w
        y2 = y1 + crop_h
        
        if x2 > width: x1 = width - crop_w; x2 = width
        if y2 > height: y1 = height - crop_h; y2 = height
        if x1 < 0: x1 = 0; x2 = crop_w
        if y1 < 0: y1 = 0; y2 = crop_h

        cropped_frame = frame[int(y1):int(y2), int(x1):int(x2)]
        if cropped_frame.size == 0:
            final_frame = frame
        else:
            final_frame = cv2.resize(cropped_frame, (width, height), interpolation=cv2.INTER_LINEAR)

        # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æç”» (active_eventãŒã‚ã‚‹å ´åˆ)
        if active_event and target_pos:
            scale_x = width / crop_w
            scale_y = height / crop_h
            def to_zoomed_pos(abs_pos):
                zx = int((abs_pos['x'] - x1) * scale_x)
                zy = int((abs_pos['y'] - y1) * scale_y)
                return (zx, zy)

            if ev_type == "spike_plant":
                sp_z = to_zoomed_pos(target_pos)
                cv2.rectangle(final_frame, (sp_z[0]-20, sp_z[1]-20), (sp_z[0]+20, sp_z[1]+20), COLOR_SPIKE, 3)
                cv2.putText(final_frame, "SPIKE PLANT", (sp_z[0]-50, sp_z[1]-30), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, COLOR_SPIKE, 2)

            elif ev_type == "focal_point":
                fp_z = to_zoomed_pos(target_pos)
                detail_name = active_event.get('type_detail', '')
                if "astra_ult" in detail_name:
                    cv2.rectangle(final_frame, (fp_z[0]-30, fp_z[1]-30), (fp_z[0]+30, fp_z[1]+30), COLOR_FOCAL, 3)
                else:
                    cv2.circle(final_frame, fp_z, 30, COLOR_FOCAL, 3)

                cat_label = active_event.get('category', 'TACTICAL').upper()
                detail_label = active_event.get('type_detail', '').replace("_", " ").upper()
                cv2.putText(final_frame, cat_label, (fp_z[0]-40, fp_z[1]-45), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, COLOR_FOCAL, 2)
                cv2.putText(final_frame, detail_label, (fp_z[0]-40, fp_z[1]+60), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR_TEXT, 1)

            else:
                killer_cls = active_event['killer']
                victim_cls = active_event['victim']
                kp = get_dynamic_pos(current_frame_int, killer_cls) or get_last_known_pos(current_frame_int, killer_cls)
                vp = None
                if current_frame_int >= active_event['frame']:
                     vp = get_dynamic_pos(active_event['frame'], victim_cls) or get_last_known_pos(active_event['frame'], victim_cls, 30)
                else:
                     vp = get_dynamic_pos(current_frame_int, victim_cls) or get_last_known_pos(current_frame_int, victim_cls, 60)
                
                if not kp and active_event.get('k_pos'):
                    raw_k = active_event['k_pos']
                    kp = {"x": raw_k['x'], "y": raw_k['y']}
                if not vp and active_event.get('v_pos'):
                    raw_v = active_event['v_pos']
                    vp = {"x": raw_v['x'], "y": raw_v['y']}

                kp_z = to_zoomed_pos(kp) if kp else None
                vp_z = to_zoomed_pos(vp) if vp else None

                if kp_z and vp_z:
                    cv2.arrowedLine(final_frame, kp_z, vp_z, COLOR_ARROW, 4, tipLength=0.3)
                if kp_z:
                    cv2.rectangle(final_frame, (kp_z[0]-15, kp_z[1]-15), (kp_z[0]+15, kp_z[1]+15), COLOR_KILLER, 2)
                    cv2.putText(final_frame, "KILLER", (kp_z[0]-25, kp_z[1]-20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLOR_KILLER, 2)
                if vp_z:
                    cv2.rectangle(final_frame, (vp_z[0]-15, vp_z[1]-15), (vp_z[0]+15, vp_z[1]+15), COLOR_VICTIM, 2)
                    cv2.putText(final_frame, "VICTIM", (vp_z[0]-25, vp_z[1]-20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLOR_VICTIM, 2)
            
            # æ 
            cv2.rectangle(final_frame, (0,0), (width, height), (0, 255, 255), 10)
            if ev_type == "focal_point": label = "CONTRIBUTION"
            else: label = ev_type.replace("_", " ").upper()
            cv2.putText(final_frame, label, (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 3)

        # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³åˆæˆ
        y_pos = height - BAR_HEIGHT - 20
        if y_pos + BAR_HEIGHT <= height:
            final_frame[y_pos:y_pos+BAR_HEIGHT, 0:width] = timeline_img
            cursor_x = int((current_input_frame / total_frames) * width)
            cv2.line(final_frame, (cursor_x, y_pos - 5), (cursor_x, y_pos + BAR_HEIGHT + 5), TL_CURSOR_COLOR, 3)

        out.write(final_frame)
        cv2.imshow("Highlight View Generator", final_frame)
        
        # --- ãƒ•ãƒ¬ãƒ¼ãƒ é€²è¡Œåˆ¶å¾¡ ---
        output_frame_count += 1
        
        # é€²è¡Œé€Ÿåº¦ã®æ±ºå®š
        if in_event:
            step = 1.0 # ç­‰å€
        else:
            step = speed_multiplier # è¨ˆç®—ã•ã‚ŒãŸå€é€Ÿ
            
        current_input_frame += step

        if cv2.waitKey(1) & 0xFF == ord('q'): break
        if output_frame_count % 50 == 0:
            print(f"\rå‡ºåŠ›ä¸­: {output_frame_count}/{target_total_output_frames} Frames (Input: {int(current_input_frame)}/{total_frames})", end="")

    cap.release()
    cap_clean.release()
    out.release()
    cv2.destroyAllWindows()
    print(f"\nâœ… å®Œæˆï¼å‡ºåŠ›: {output_path}")

if __name__ == "__main__":
    create_tracking_highlight("base_minimap.mp4", "match_data.json", "Final_Tracking_30s.mp4")